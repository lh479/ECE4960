<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <meta name="description" content="">
        <meta name="author" content="">
        <title>ECE4960 Robby</title>
        <!-- Font Awesome icons (free version)-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js" crossorigin="anonymous"></script>
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet">
        <!-- Fonts CSS-->
        <link rel="stylesheet" href="css/heading.css">
        <link rel="stylesheet" href="css/body.css">
    </head>
    <body id="page-top">
        <nav class="navbar navbar-expand-lg bg-secondary fixed-top" id="mainNav">
            <div class="container"><a class="navbar-brand js-scroll-trigger" href="#page-top">FAST ROBOTS</a>
                <button class="navbar-toggler navbar-toggler-right font-weight-bold bg-primary text-white rounded" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">Menu <i class="fas fa-bars"></i></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ml-auto">
                        <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#portfolio">LABS</a>
                        </li>
                        <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#about">ABOUT ME</a>
                        </li>
                        <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="#contact">CONTACT</a>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
        <header class="masthead bg-primary text-white text-center">
            <div class="container d-flex align-items-center flex-column">
                <!-- Masthead Avatar Image--><img class="masthead-avatar mb-5" src="assets/img/PngItem_713104.png" alt="">
                <!-- Masthead Heading-->
                <h1 class="masthead-heading mb-0">ECE4960 | FAST ROBOTS</h1>
                <!-- Icon Divider-->
                <div class="divider-custom divider-light">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- Masthead Subheading-->
                <p class="pre-wrap masthead-subheading font-weight-light mb-0">Robby Huang | ECE 2022</p>
            </div>
        </header>
        <section class="page-section portfolio" id="portfolio">
            <div class="container">
                <!-- Portfolio Section Heading-->
                <div class="text-center">
                    <h2 class="page-section-heading text-secondary mb-0 d-inline-block">LABS</h2>
                </div>
                <!-- Icon Divider-->
                <div class="divider-custom">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- Portfolio Grid Items-->
                <div class="row justify-content-center">
                    <!-- Portfolio Items-->
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal0">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div><img class="img-fluid" src="assets/img/Lab1.png" alt="Lab1"/>
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal1">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div><img class="img-fluid" src="assets/img/Lab2.png" alt="Lab2"/>
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal2">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div><img class="img-fluid" src="assets/img/Lab3.png" alt="Lab3"/>
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal3">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div><img class="img-fluid" src="assets/img/Lab4.png" alt="Lab4"/>
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal4">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div><img class="img-fluid" src="assets/img/Lab5.png" alt="Lab5"/>
                        </div>
                    </div>
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-toggle="modal" data-target="#portfolioModal5">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div><img class="img-fluid" src="assets/img/Lab6.png" alt="Lab6"/>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- Portfolio Modal-->
        <div class="portfolio-modal modal fade" id="portfolioModal0" tabindex="-1" role="dialog" aria-labelledby="#portfolioModal0Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true"><i class="fas fa-times"></i></span></button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary mb-0">Lab 1: The Artemis Board</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    
                                    <!-- Portfolio Modal - Text-->
                                    <p align="left">The purpose of this lab is to help us set up IDE and run some simple scripts on the Artemis board. By running blink, serial communication, analog read of the temperature sensor, and frequency measurement by the Pulse Density Microphone, I was familiarized with the basic features of the board. </p>
                                    <iframe src = "https://www.youtube.com/embed/RLJkmN6ZvMs"
                                    width="540" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">In this first demo, I blinked the board. To successfully compile the script on my Mac I need to upgrade my Arduino IDE from 1.8.9 and decrease the SVL baud rate to <code>115200</code> bits per second. </p>
                                    <iframe src = "https://www.youtube.com/embed/Ba4FY0rEfFk"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">In the second example, I ran the example code on serial communication. Since we are only using the serial communication on the Type-C cable and the example code printed out messages on both UART channels, I modified the code so that everything printed out from the USB one. The <code>Serial.print()</code> function will allow you to send out information over UART. The video demonstrates both input and output with UART. </p>
                                    <iframe src = "https://www.youtube.com/embed/HXBCVLbETWs"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">In the third demo, I ran the analogRead example code and visualized the gradual temperature change on the temperature sensor caused by touching the chip on the serial monitor. Reading the analog value on an analog pin can be accomplished by calling the <code>analogRead()</code> function.</p>
                                    <iframe src = "https://www.youtube.com/embed/MVGxjuh36y8"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left"> The fourth demo showed the display of the highest frequency heard by the microphone on the board. After I ran the MicrophoneOutput example code, the highest frequency of the surrounding sound was displayed on the serial monitor. In the code, it first converts the PDM samples to floats in this line <p> <code>g_fPDMTimeDomain[2 * i] = pi16PDMData[i] / 1.0;</code> 
                                    <p align="left">and then perform FFT with the <code>arm_cfft_f32</code> function. Lastly, it finds the frequency bin with the largest magnitude and prints it on the serial monitor. As I whistled in higher and higher frequencies, the number displayed on the serial monitor increased. </p>
                                    <iframe src = "https://www.youtube.com/embed/q9I3fyrfy0I "
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">In the last demo, I slightly modified the microphoneOutput example. By using and <code>if/else</code> conditional statement with the variable <code>ui32MaxIndex</code>. 
                                    Code snippet that I added: </p>
                                    <img class="img-fluid" src="assets/img/Lab1Code.png">
                                    <p></p><p align="left">As you can see in the video, the on board led blinked when I whistled. 
                                    <p>

                                    <button class="btn btn-primary" href="#" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-labelledby="#portfolioModal1Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true"><i class="fas fa-times"></i></span></button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary mb-0">Lab2: Bluetooth</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    
                                    <!-- Portfolio Modal - Lab2-->
                                    <p align="left">The objective of this lab is to establish Bluetooth communication between the Artemis and the computer. We need to implement Arduino code on the Artemis side and Python in Jupyter Notebook on the computer. The purpose of this is to offload computation to the computer later when we are performing computationally intensive tasks on the robot.</p>
                                    <p class="pre-wrap lead mb-3">Setup</p>
                                    <p align="left">The first step was to set up the environment on the computer side. I initially tried to install Jupyter Lab on my Mac computer. However, since my Mac was still running MacOs 10, Jupyter Lab failed to open.</p>
                                    <img class="img-fluid" src="assets/img/lab2:1.png">
                                    <p align="left">I eventually switched to Ubuntu 20.02 and successfully ran Jupyter Server in my virtual environment. </p>
                                    <p align="left">The MCU setup was much easier. We just need to install the ArduinoBLE library and upload <code>ble_arduino.ino</code> to the Artemis board. If uploaded successfully, we should be able to see the MAC address of the board on Serial Monitor.</p>
                                    <p class="pre-wrap lead mb-3">Bluetooth Connection</p>
                                    <p align="left">To establish the connection between the Artemis board and the computer with BLE, I matched the MAC address defined in connection.yaml to the one on Arduino serial monitor. This message should be displayed when the connection is established.</p>
                                    <img class="img-fluid" src="assets/img/Lab2:2.png">
                                    <p class="pre-wrap lead mb-3">Demo</p>
                                    <p align="left">With the help of the demo code, I performed the following tasks: receiving float and string using <code>receive_float()</code> and <code>receive_string()</code> functions, sending commands, and disconnecting. Here is a short video running the tasks in the demo code.</p>
                                    <iframe src = "https://www.youtube.com/embed/j6YbJds9qWs"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p class="pre-wrap lead mb-3">Tasks</p>
                                    <p align="left">Before I demonstrate my tasks, I need to run the script to import necessary modules and run the connect command. </p>
                                    <iframe src = "https://www.youtube.com/embed/FGkSLJ77dJ4"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">TASK ONE: 
                                        The first task is to send an <code>ECHO</code> command with a string input that will trigger the Artemis board to return an augmented string to the computer. On the Artemis side, commands are handled by the switch/case statement. In the <code>ECHO</code> case, I first initialized a char array and then use the get value function to extract the string from the command string. After obtaining the input string, the next step is to augment the array and send it back to the computer. First I emptied the contents of the tx_estring_value, then use <code>append()</code> function to augment it. Lastly, I send the augmented string out with the writeValue commend. For debugging purposes, I also print it on the serial monitor. 
                                        </p>
                                        <img class="img-fluid" src="assets/img/ECHO.png">
                                    <p align="left">In my code, I augmented my message with “My boss said:”, so the board would repeat my message while referring me as his boss. In this demo video, I sent the commend using <code>send_commend(CMD.ECHO, “hi”)</code> and I got "My boss said: hi” from the board. </p>
                                    <iframe src = "https://www.youtube.com/embed/_06IpDADzYU"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">TASK TWO: 
                                        Sending three floats is very similar to the example <code>SEND_TWO_INTS</code>. I first declared three float variables and then used <code>get_next_value(float)</code> function to write the three floats to the variables. On the computer side, I sent three floats 1.2, 3.42, and -21.32 to cover test cases with different decimal places and different signs.                                         
                                        </p>
                                        <img class="img-fluid" src="assets/img/Send3F.png">
                                    <iframe src = "https://www.youtube.com/embed/vQMTR___Y1E"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">TASK THREE: 
                                        The notify mechanism in BLE will trigger the handler (or callback function) when data is changed. It is similar to an interrupt and an ISR. The only thing we need to do on the Arduino side is to define a UUID associated with a float. In this case, I am using the declared tx_characteristic_float, which increments 0.5 every half a second. 
                                        On the computer side, I called the <code>start_notify(uuid, handler)</code> function. It was quite confusing for me that the handler requires two parameters, yet the notify function only takes uuid and the handler itself as inputs. I later discovered that we could declare an input for the handler function outside the scope of the function. I used <code>read(uuid)</code> function to read the input byte array and store it in variable inputf as the second input of the handler function. The handler function then basically converted the byte array into float and store it in a global variable. The global variable will keep updating unless the function <code>stop_notify(uuid)</code> is called. 
                                        <img class="img-fluid" src="assets/img/notify.png">
                                        </p>
                                    <iframe src = "https://www.youtube.com/embed/FrYCEU2hdT4"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left"> Remember to disconnect. 
                                        </p>
                                    <iframe src = "https://www.youtube.com/embed/eQ1JXguyodQ"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">TASK FOUR: 
                                        The two approaches can all successfully deliver a float with the same accuracy. When sending numbers one by one, both approaches have identical speeds. The benefit of using <code>receive_float()</code> is that, it is more direct and does not require data type conversion. This approach is ideal for debugging but expensive computationally. If we send a large number of data quickly, it is more memory efficient and faster to combine sensor readings into a single <code>BLECStringCharactersitic</code> on the Arduino side and unpacked it when it reached the computer side. This would be useful when we need to stream, for example, accelerometer readings rapidly when the robot is moving fast. We need to be aware of the max message size (150 byte) when implementing this.                                        
                                        </p>


                                    <button class="btn btn-primary" href="#" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-labelledby="#portfolioModal2Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true"><i class="fas fa-times"></i></span></button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary mb-0">Lab3: Sensors</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Lab3 - Text-->
                                    <p class="pre-wrap lead mb-3">Objective </p>
                                    <p align="left">The purpose of this lab is to let us familiarize ourselves with TOF and IMU, the two important sensors that we will equip on the robot. We should first understand the sensor so that we can use it to collect useful data such as the distance of obstacles and pitch, roll, and yaw. Furthermore, we should learn the limit and constrain of our sensors such as sample rate, noise, range, and accuracy. 
                                    <p class="pre-wrap lead mb-3">Time-of-Flight Sensor </p>
                                    <p align="left">Wiring </p>
                                    <img class="img-fluid" src="assets/img/Lab3Wiring.jpg">
                                    <p align="left">1. I ran the I2C example script to scan I2C addresses for the sensors. When I turned both of them on, the serial window displayed all the I2C addresses. When I turned one of them off, I found address <code>0x29</code>. This is expected according to the Sparkfun page for this sensor.</p>
                                    <p align="left">2. The ToF sensor has three distance modes. Short distance mode is more immune to ambient light, but its maximum ranging distance is limited to 1.3m, compared to 4m of the long distance mode. Meanwhile, long distance mode allows the longest possible ranging distance but is easier to be impacted by ambient light. Different distance modes also affect the timing budget. In short distance mode, 2oms is the minimum timing budge and 140ms is the timing budget allows for the long distance mode. Increasing the timing budget increases the average power consumption and can improve the repeatability error. On the final robot, both modes would be helpful. We could use one mode for each TOF sensor and perform sensor fusion. Given the size of the robot, we are probably going to operate at short or short/mid range mode.</p>
                                    <p align="left">3. I examined the sensor range, accuracy, repeatability, and ranging time. I also tried to compare sensor reading with different light conditions and surface textures. I used a 1.3-meter tape measure to measure the distance of a flat surface from the TOF sensor mounted vertically. All testing data below are based on the average of 100 sample points per measurement. </p>
                                    <img class="img-fluid" src="assets/img/Lab3:1.png">
                                    <p align="left">In short distance mode, the sensor has a range between 30mm to 1250 with less than 10% of error. The accuracy was consistently high until it reaches more than 800mm, at which the percentage error starts increasing linearly. </p>
                                    <img class="img-fluid" src="assets/img/Lab3:2.png">
                                    <p align="left">The standard deviation of 100 sample points at each distance can tell us how steady the measurement is at that distance. Similar to the accuracy curve, the consistency of measurement decreases beginning at the 800mm point exponentially. </p>
                                    <img class="img-fluid" src="assets/img/Lab3:3.png">
                                    <p align="left">In this chart, I compared the TOF collecting data in different environments and from different surfaces. We can see that less ambient light will make the data more accurate and consistent and different surface textures correspond to different accuracy because it deflects light a bit differently.  </p>
                                    <p align="left">The standard deviation of 100 sample points at each distance can tell us how steady the measurement is at that distance. Similar to the accuracy curve, the consistency of measurement decreases beginning at the 800mm point exponentially.  </p>
                                    <p align="left">I also try to print out the ranging time of the sensor. The time between when <code>startRanging()</code> is called to when <code>stopRanging()</code> is called does not change linearly with the obstacle distance. If the obstacle is in range, the ranging time is about 52144 microseconds and if the obstacle is out of range, the ranging time is 32064.  </p>
                                    <p align="left">I accomplished daisy chaining the two TOF sensors by manually toggling the XSHUT pins with GPIOs at appropriate times. I first turned all the sensors off by pulling their XSHUT pins LOW and then turning them on one at a time while setting the I2C address of the first one to prevent address conflict. To ensure this process is successful, I printed out the output of <code>distanceSensor1.getI2CAddress()</code> to see the new address and using this logic:
                                    <code>
                                        if (distanceSensor1.getI2CAddress() !=distanceSensor2.getI2CAddress()) {
                                            Serial.println("No conflicts!");
                                        }</code>
                                        to ensure that the addresses are not conflicting. 
                                         </p>
                                    <p align="left">Demo video for two TOF sensors working at the same time： </p>
                                    <iframe src = "https://www.youtube.com/embed/wthItQdLOUI"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p class="pre-wrap lead mb-3">Inertial Measurement Unit </p>
                                    <p align="left">After I wired the IMU to the Artemis board I scan the I2C channel to find the sensor’s address. I found <code>0x68</code>, which is expected because the datasheet indicated that the I2C address for this sensor is either <code>1101000</code> or <code>1101001</code> in binary depending on the AD0 value. To run Example1_Basics.ino, we need to change the AD0_VAL to 0 since from the datasheet we learned that address <code>0x68(1101000)</code> corresponds to <code>AD0 = 0</code>.</p>
                                    <p align="left">I am able to see both scaled and raw accelerometer and gyroscope data when running the example code. I plotted them out on the serial plotter so that I can visualize them. In the accelerator plot, we can see some noisy acceleration data in X, Y, and Z directions. Depending on the orientation of the sensor, some acceleration is always detected when the sensor is stationary due to gravity. 
                                    </p>
                                    <img class="img-fluid" src="assets/img/Lab3Acc.png">
                                    <p align="left">The gyroscope measures the angular velocity. Its plot looks noisy and it is very sensitive to changes in velocity without any filtering. </p>
                                    <img class="img-fluid" src="assets/img/Lab3Gyro.png">
                                    <p align="left">Accelerator</p>
                                    <p align="left">Pitch and roll are calculated by these lines of code: </p>
                                    <p align="left"><code>pitch = 180 * atan2(myICM.accX(),myICM.accZ())/M_PI;</code></p>
                                    <p align="left"><code>roll  = 180 * atan2(myICM.accY(),myICM.accZ())/M_PI;</code></p>
                                    <p align="left">We cannot calculate the yaw value with accelerometer data because we can’t use gravity as a reference acceleration in the XY plane.</p>
                                    <p align="left">In this demo video, I am showing the output at {-90, 0, 90} degrees pitch and roll. The output is relatively accurate</p>
                                    <iframe src = "https://www.youtube.com/embed/MuK-JwMk45o"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">The next step is calibration. I measured pitch and roll to have the range of pitch[-89,89], Roll [-88,85], which means it has an accuracy of >95%. To calibrate it, I used the map function. For example, to map pitch to [-90,90]: <code>pitch = map(pitch, -89, 89, -88, 85);</code> </p>
                                    <p align="left">Gyroscope</p>
                                    <p align="left">In order to find the frequency of the unwanted noise in the output signal, we need to perform Fast Fourier Transform on the dataset. I set a timer in the code to make it stop collecting data after 10 seconds so that the data length is known and consistent. My dataset has a length of 288 and a sampling period of 3.3150e-2s. I exported the data and performed FFT in Matlab. 
                                    </p>
                                    <img class="img-fluid" src="assets/img/Lab3Matlab.png">
                                    <p align="left">I performed FFT on a noisy dataset, which I collected while tapping the sensor, and a dataset with limited noise to distinguish the noise frequency buckets in the frequency spectrum. </p>
                                    <img class="img-fluid" src="assets/img/NoiseP.PNG">
                                    <img class="img-fluid" src="assets/img/NoiseR.PNG">
                                    <p align="left">I also did FFT on a regular dataset.</p>
                                    <img class="img-fluid" src="assets/img/NoNoiseP.PNG">
                                    <img class="img-fluid" src="assets/img/NoNoiseR.PNG"> 
                                    <p align="left">As you can see, the useful data are mostly at less than 1Hz. If fc = 1, RC = 0.159. Since alpha = T/(T+RC)  and T = 0.03315s, <code>alpha = 0.03315/(0.03315+0.159) = 0.1725</code>. With this alpha, I am able to achieve a plot with less noise:</p>
                                    <iframe src = "https://www.youtube.com/embed/Bz7A5F3gzOM"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">We can tell the alpha value is appropriate because the readings react to changes in a short enough time, so the time constant is not too big.</p>
                                    <p align="left">Gyroscope</p>
                                    <p align="left">Gyroscope provides us the angular velocity of the sensor. We can simply multiply the velocity with the dt between the sampling intervals to find the angular displacement. We can find dt with the help of a variable and the <code>micros()</code> function: </p>
                                    <p align="left"><code>dt = (micros() - last_time) /1000000;</code></p>
                                    <p align="left"><code>last_time = micros(); </code></p>
                                    <p align="left">and calculate roll, pitch and yaw with: </p>
                                    <p align="left"><code>roll_g = roll_g + myICM.gyrX() * dt;                                    </code></p>
                                    <p align="left"><code>pitch_g = pitch_g - myICM.gyrY() * dt;
                                    </code></p>
                                    <p align="left"><code>yaw_g = yaw_g + myICM.gyrZ() * dt;
                                    </code></p>
                                    <p align="left">The sign between the two terms could change depending on the sensor orientation.</p>
                                    <p align="left"><code></code></p>
                                    <p align="left">This serial plot is plotting the angle displacement output calculated from the accelerometer and gyroscope without any filter. One can see that the output calculated from the accelerometer is much noisier than the one from the gyroscope. </p>
                                    <img class="img-fluid" src="assets/img/lab3gryoacc.png">
                                    <p align="left">We can do a more direct comparison between the filtered data by accelerometer and gyroscope. </p>
                                    <iframe src = "https://www.youtube.com/embed/Ge62Un_VXSE"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">Although the data synchronized at the beginning of the demo, there are a few distinguishing differences between them. 1. Gyroscope data rely on the initial condition, but accelerometer does not. 2. Though the gyroscope is less noisy, its data are likely to drift, especially after some rapid changes in data. Meanwhile, accelerometer data will not drift since it uses gravity as the reference. 3. Data from the gyroscope can go above 90degree and the accelerometer’s data has a range between [-90,90]. </p>
                                    <p align="left">I tried decreasing the sampling frequency of the system. Obviously, data will be displayed at a slower rate. More importantly, the increase in sampling interval introduced more noise and inaccuracies in approximating the angular displacement. Thus, the data is more likely to drift. </p>

                                    <p align="left">Since both sensors have pros and cons, we can use a complementary filter to produce a final data output with less noise and high accuracy. Here, we need to double-check the sign of the myICM.gyrY() term. Since the frequency of potential noises is similar to the one we found, we could just use the same alpha value. </p>
                                    <p align="left"><code>pitch = (pitch - myICM.gyrY()*dt) * (1-alpha) + pitch_a * alpha;
                                    </code></p>
                                    <p align="left"><code>roll = (roll + myICM.gyrX()*dt) * (1-alpha) + roll_a * alpha;
                                    </code></p>
                                    <img class="img-fluid" src="assets/img/combineAccGyro.png">
                                    <p align="left">In this plot, the red line is data from the gyroscope, the blue curve is the low pass accelerator data, and the green one is from the output of the complementary filter. The red curve is drifted and the blue curve is a bit noisier than the green one.  </p>
                                    <iframe src = "https://www.youtube.com/embed/618lhaL_uTU"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">In this final demo video, I demonstrated the IMU getting accurate pitch and roll in the full range with relatively low noise. The yaw value (the green line), is only computed from the gyroscope data, so it is subject to drifting.   </p>
                                    <button class="btn btn-primary" href="#" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                    
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-labelledby="#portfolioModal3Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true"><i class="fas fa-times"></i></span></button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary mb-0">Lab4: Characterize Your Car</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Lab4 - Text-->
                                    <p class="pre-wrap lead mb-3">Objective </p>
                                    <p align="left">After learning about sensors in our previous lab, we learnt about the potential and limitations of our car in this lab. With the help of the remote control and IMU, my partner (Jack Defay) and I designed a series of tests to explore the ability of the RC car. 
                                    <p class="pre-wrap lead mb-3">Testing Method </p>
                                    <p align="left">While most of the tests relied on basic lab equipment such as rulers, scales, and stopwatches, we used Bluetooth to stream data from IMU during our test runs to obtain more interesting and informative data. </p>
                                    <p align="left">To establish such a connection, we used the <code>tx_estring_value.append(float value) </code>function and <code>tx_characteristic_string.writeValue(tx_estring_value.c_str()) </code>function to update the <code>BLE_TX_STRING</code> with <code>uuid “f235a225-6735-4d73-94cb-ee5dfce9ba83”</code>. On the Python side, we called the <code>start_notify</code> function to access that uuid and stream the changed data. We packaged all the float data into a string and update it at each cycle so the data is well-formatted and more memory efficient. Such connection enabled us to test the robot untethered while keeping all the sensor values well documented. </p>
                                    <p align="left">Since gyroscope reading tends to drift a lot while we are transferring the robot before testing, I made this <code>ZEROGYRO</code> commend so that we can zero the initial condition before each test to obtain cleaner test results. </p>
                                    <img class="img-fluid" src="assets/img/lab4:1.png">
                                    <p class="pre-wrap lead mb-3">Dimension </p>
                                    <p align="left">I used rulers and calipers to obtain accurate measurements for the car. Dimensions are important in robotics since it defines the local frame of the robot and directly affects the robot’s dynamics. Dimensions are shown in this picture in millimeters. </p>
                                    <img class="img-fluid" src="assets/img/Lab4:2.png">
                                    <p class="pre-wrap lead mb-3">Weight </p>
                                    <p align="left">I used a scale to measure the weight of the robot and the weights of its battery. 
                                    </p>
                                    <img class="img-fluid" src="assets/img/IMG_5500.jpg">
                                    <img class="img-fluid" src="assets/img/IMG_5502.jpg">
                                    <p class="pre-wrap lead mb-3">Battery </p>
                                    <p align="left">To understand the battery and the power consumption of car better, I did an unloaded discharged test. I used the 650mAh 1S Lipo battery that comes with the car and run the car unloaded continuously. </p>
                                    <img class="img-fluid" src="assets/img/lab4:7.png">
                                    <p align="left">I obtained this discharge curve, which is a quite normal Lipo discharge curve. The car requires 3V minimal to run. A 3V battery typically corresponds to 10% SoC(state of charge). If we hang the car up with wheels off the ground, we get about 20 minutes of run time. I already tried to power the car with a DC power supply, but it doesn’t seem to be working due to the high ripple in the current drain.</p>
                                    <p class="pre-wrap lead mb-3">Turning Resolution </p>
                                    <p align="left">We wanted to figure out the turning resolution of the robot with remote control and IMU sensor so that we can better control the robot’s turning motion in the future. With gyroscope data (plotted below), we are able to see how much the robot turns when we press the button on the remote as short as possible.  </p>
                                    <img class="img-fluid" src="assets/img/Lab4:3.png">
                                    <p align="left">After using all the data and calculating the delta yaw at each turn, I found that the minimum turning with the remote control is about 40 degrees. </p>
                                    <img class="img-fluid" src="assets/img/lab4:4.png">
                                    <p class="pre-wrap lead mb-3">Ground Flipping </p>
                                    <p align="left">In this task, we would like to find out the minimum runup distance require to flip the RC car. To visualize the flipping motion, we plot the gyroscope data out during the run-up and flipping process.  </p>
                                    <img class="img-fluid" src="assets/img/lab4:5.png">
                                    <p align="left">As you can see, the robot performed a 360 flip here. The steps behind the flipping motion involve 1. The car to</p>
                                    <p align="left">The steps behind the flipping motion involve 1. The car ramps up to a certain speed. 2. The car breaks and the back of the car will be lifted up due to inertia. 3. The front wheel starts to spin in a reverse direction, while the back of the car keeps going to the front in the air. 4. Finish flipping. Given this process, the most important parameter would be the lowest initial speed. We characterized this by starting the car from a full stop and calculating the minimal distance to flip. We took videos to check the run-up distance at the frame that the car starts to flip and we obtained the following data. </p>
                                    <img class="img-fluid" src="assets/img/lab4:6.png">
                                    <p align="left">From the data from the 18 trials, 15 of them succeeded while 3 of them failed. We can see that 3 feet should be adequate for the robot to run up and flip.</p>
                                    <p align="left">Testing video:</p>
                                    <iframe src = "https://www.youtube.com/embed/WovTeWXbvu8"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p class="pre-wrap lead mb-3"> Ramp-Up Time</p>
                                    <p align="left">From observation, we concluded that the car ramps up to its highest speed in roughly 10 feet. We took multiple videos and calculated the time difference between the frame that the car started and the frame that the car crossed the 10 feet line. The data showed that the car took an average of 1.24 seconds to ramp up. The data has a small standard deviation of 1.108, so it is consistent.</p>
                                    <p align="left">Testing video:</p>
                                    <iframe src = "https://www.youtube.com/embed/umNwGOdhxLk"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p class="pre-wrap lead mb-3"> Bi-Pedal Motion</p>
                                    <p align="left"> During testing, we discovered this interesting motion of the car that happens when the car is sideway. When we oscillate between the two turning directions quickly, the car will achieve fish-like locomotion.</p>
                                    <iframe src = "https://www.youtube.com/embed/y_OgnBC79zs"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">With the help of the IMU, we are able to track the pitch of the car when performing such a motion. 
                                    </p>
                                    <img class="img-fluid" src="assets/img/Lab4:8.png">
                                    <p align="left">Each movement can be further broken down into left commend, right commend, and left commend. We characterized this motion but counting the direction of the left and right spinning of the motor. We compared the good runs (red curves) and bad runs (blue curves) in the curves below and found the optimal range for motor spinning duraction to be around 0.3 seconds. Later when we are controlling the robot with PWM signals, we can ensure such duraction when it is doing the bipedal movement. 
                                    </p>
                                    <img class="img-fluid" src="assets/img/Lab4:9.png">

                                    <button class="btn btn-primary" href="#" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-labelledby="#portfolioModal4Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true"><i class="fas fa-times"></i></span></button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Lab 5-->
                                    <h2 class="portfolio-modal-title text-secondary mb-0">Lab5: Open Loop Control</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Text-->
                                    <p class="pre-wrap lead mb-3">Objective </p>
                                    <p align="left">
                                        In this lab, we start to run the car with our own control circuits and algorithm. With our own control system, we can control the exact speed and duration of each motor. This will set a solid foundation for closed-loop control and, more importantly, allow us to replicate the stunts we characterized later. 
                                        </p>
                                    <p class="pre-wrap lead mb-3">Wiring </p>
                                    <p align="left">
                                        Wiring is a crucial part of the lab. A clean, neat, and secure wiring will allow us to have a smooth testing process and obtain data without much noise. First of all, I took the car apart and cleaned the original circuitry out. There are a few requirements I hope to meet with the placement of all the components:
                                        </p>
                                    <p align="left">
                                        1. All components need to be securely mounted and in a position with enough space.
                                            </p>
                                    <p align="left">
                                         2. IMU should stay away from the DC motors so the accelerometer is less disrupted by the motor EMI noise.</p>
                                    <p align="left">
                                            3. Components with a lot of connections to each other should stay close together.</p>     
                                    <p align="left">Therefore, I decided to place the IMU in the front platform, one TOF in the front and one on the side, two motor drivers in the rear cabin with all the batteries, next to the motors and the Artemis. </p> 
                                    <p align="left">There are two h-briges on the <code>DRV8833</code> IC. To increase the maximum current we can deliver to each motor, we use one driver per motor by parallelling its two channels. This is a creative solution when we do not have a single h-bridge that can handle the amount of current we would like to deliver. </p> 
                                    <p align="left">To make debugging hardware easier, I decide to connect different parts of the system securely while making them detachable from each other. Therefore, half of my connection to the boards is soldered and the other half is male/female header connection. Knowing that all GPIO pins on Artemis Nano have PWM capability and saving space, I only put headers between A2-8 pins on the board. </p>
                                    <p align="left">Placement of components: </p>
                                    <img class="img-fluid" src="assets/img/lab5placement.png">
                                    <p align="left">I used soft wires to wire all the components together and color-coded them with standard conventions: red for 3V3, black for GND, etc. To reduce EMI between sensors and actuators, I twisted all wires with high-frequency signals together so that the overall branch has a net current of zero. I further protected the circuit by using zip ties to lessen the stress on the solder joints. I also cut the wires so that they could all fit on the chassis but not be too tight. I used electrical tape to isolate components from shorting each other during the runs and use Gorilla tape to securely mount the sensors on flat platforms on the robot. </p>
                                    <p align="left">Final layout:
                                    </p>
                                    <img class="img-fluid" src="assets/img/lab5wiring.jpg">
                                    <p class="pre-wrap lead mb-3">Motor Driver </p>
                                    <p align="left">When we power a system for the first time, it is usually a good idea to power it with a DC power supply. For this implementation, the power supply is acting as a 1S Lipo battery so I set it to 3.7V (the nominal voltage of a 1S Lipo battery) and turn the current limit to 3A since the motor driver allows up to 1.5A per channel. The battery we will end up using is a 25C 850mAh Lipo battery, which can output up to <code>25C* 0.85Ah = 21.25A</code>. Later we will use two different batteries. One power the Artemis and all the sensors and the other provides power for the DC motors. The first one will probably be drawing current at a milliampere level while the other would go up to more than 5 amps. Since the motor draws a lot of currents and its current draws changes rapidly, it would be a good idea to separate the high power and low power path and their power sources. 
                                    </p>
                                    <p align="left">I used PWM to control the output level of the motor driver following this chart:
                                    </p>
                                    <img class="img-fluid" src="assets/img/lab5chart.png">
                                    <p align="left">Since all GPIO pins on Artemis have PWM channels, we can simply call analogWrite(pin, level) function to output a PWM from 0-255. Here, I demonstrated my ability to control the PWM duty cycle on pin A2 with a loop that steps the PWM from 0 to 255.
                                    </p>
                                    <img class="img-fluid" src="assets/img/lab5code1.png">
                                    <!-- scope-->  
                                    <iframe src = "https://www.youtube.com/embed/1uajJRABDew"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">To power one motor, we just need to set one pin connected to the input to LOW and the other to a PWM pulse. For example, <code>analogWrite(A3,0); analogWrite(A2,200); </code>
                                        In the following demo videos, I demonstrated that the wheels can spin in all directions with proper PWM input from the Artemis. I started with one wheel, then started to control both wheels.                                        
                                    </p>
                                     <!-- 1wheel-->  
                                     <iframe src = "https://www.youtube.com/embed/42XXbOofmow"
                                     width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                     <!-- 1wheel-->  
                                     <iframe src = "https://www.youtube.com/embed/lL5KUV5moDY"
                                     width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                     <!-- 2 wheels-->  
                                     <iframe src = "https://www.youtube.com/embed/aa7RbZNYHA8"
                                     width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">I then further characterized the input to these functions, so I know how the PWM will make the car move.
                                    </p>
                                    <img class="img-fluid" src="assets/img/lab5code2.png">
                                    <p class="pre-wrap lead mb-3">Open Loop Control </p>
                                    <p align="left">This was what happened, when I ran the car on the floor with the battery plugged in. Although I added a timer to stop the movement after two seconds, it was still too moving too fast and not at a straight line. 
                                    </p>
                                    <iframe src = "https://www.youtube.com/embed/Smuuu7fAajw"
                                     width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">The functions I created in the previous sections were nice, but keep reprogramming the board is quite annoying. Therefore, I made a separate command for each one of them. 
                                    </p>
                                    <img class="img-fluid" src="assets/img/lab5code3.png">
                                    <p align="left">After connecting to Bluetooth with my computer, I can simply run commend like <code>ble.send_command(CMD.FORWARD, "")</code> 
                                    and <code>ble.send_command(CMD.CWTURN, "") </code>
                                        
                                        To make the car perform certain tasks.                                        
                                    </p>
                                    <img class="img-fluid" src="assets/img/lab5code4.png">
                                    <p align="left">This command will allow the user to input the PWM level of all the motors to set the speed of the car immediately with this line of code in Python.
                                       <code>ble.send_command(CMD.SETSPEED, "255") </code> 
                                        Since it is moving to the left when I commanded it to go straight, I tried adding some calibration factor on the left motor to make it go a bit faster than the right one and found that a factor of 1.1 works the best. <code>analogWrite(A2,motorspeed*1.1);</code>
                                        In this demo, the remote control car moves fairly straight. The string under the car is 2 meters long.                   
                                    </p>


                                    <!-- straight demo-->  
                                    <iframe src = "https://www.youtube.com/embed/ANKu8Zj6XOM"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>

                                    <p align="left">With the SETSPEED commend, we can also easily find the minimal PWM duty cycle to make the car move. When the battery is at 4V, the car moves when the PWM level is 49 (which means a duty cycle of <code>49/255 = 19.2%</code>). This video shows the difference between the car moving forward at 19.2% duty cycle and 18.2% duty cycle. When I ran it with a speed of 48, the car could no longer move forward smoothly.</p>
                                    <iframe src = "https://www.youtube.com/embed/WEBsITOBh4k"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>

                                    
                                    <p align="left">For the final demo, I showed the car moving with these command sequences over Bluetooth. Turning requires the motor to spin harder so I set the speed to 255 before calling the turning commands. Overall, the robot could received and performed the commands accurately.      
                                    </p>
                                    <img class="img-fluid" src="assets/img/lab5com.png">
                                    <!-- final demo-->    
                                    <iframe src = "https://www.youtube.com/embed/QKOxmwcW91o"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <button class="btn btn-primary" href="#" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-labelledby="#portfolioModal5Label" aria-hidden="true">
            <div class="modal-dialog modal-xl" role="document">
                <div class="modal-content">
                    <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true"><i class="fas fa-times"></i></span></button>
                    <div class="modal-body text-center">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary mb-0">Lab 6: Closed-loop control </h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    
                                    <!-- Portfolio Modal - Text-->
                                    <p class="pre-wrap lead mb-3">Objective </p>
                                    <p align="left">
                                        After we performed open-loop control in the previous lab, we are moving forward to closed-loop control. Closed-loop control, especially PID control, is a simple and elegant way to accurately control the robot. This lab allows us to set up the basis for impressive stunts later. We can practice implementing PID control from scratch and implementing it on the physical robot. Doing so is more challenging than tuning PID with equations in a simulator, but it encourages thinking about elements such as noise and sampling speed in a real-life scenario. I choose to implement task B for this lab. 
                                        </p>
                                    <p class="pre-wrap lead mb-3">Debugging Framework </p>
                                    <p align="left">
                                        First and foremost, we need to set up a user-friendly debugging environment so that we can implement a PID controller more efficiently later. I first allocated memory for a few 500-element arrays. Based on the sample speed of the IMU, 500 data points will take about 5 seconds to be filled, which should be long enough to perform the task. I created the following arrays for debugging or tuning PID. 
                                        </p>
                                    <p align="left">
                                        To send them over in a clean and speedy manner, I decided to make a <code>SENDDATA</code> commend, in which I made a for loop with 500 interactions. In each iteration, I cleared the <code>tx_estring_value</code> and appended all the debugging data on it. Therefore, all the data can be associated with the correct timestamp. 
                                            </p>
                                            <img class="img-fluid" src="assets/img/Lab6:1.png">
                                    <p align="left">
                                        On the Python side, I declared a list “readings”  to store all the strings. I called the start_notify function to monitor any changes in the <code>RX_STRING</code>. In the handler, I appended the transferred strings to the list. Once the handler was established, I called the <code>SENDDATA</code> commend. Usually, after about 20 seconds, all the data are transferred and I used a for loop to print out the readings: </p>
                                        <p align="left"><code>for f in readings:</code></p>
                                        <p align="left"><code>print(f)</code> </p>
                                        <p align="left">The readings are printed out in one row per timestamp format with commas separating different data. I can copy the data and plot them in Google Sheet.
                                    </p>
                                    <img class="img-fluid" src="assets/img/lab6:2.png">
                                    <p align="left">
                                        To reduce the number of compilations I need to do, I created two helper commends <code>SETPIDVALUE</code> and <code>SETSETPOINT</code>. I call them in the Python code so I can tune my PID values and change the setpoint quickly. 
                                        <code>ble.send_command(CMD.SETPIDVALUE, "4|0|0.5")</code>
                                        <code>ble.send_command(CMD.SETSETPOINT, "0")</code>
                                    </p>
                                    <p align="left">
                                        On the Arduino side, I used the function from the ble library to update global variables such as Kp, Ki, Kd, and setPoint. For example, to update the Kp value from user input, I used <code>success = robot_cmd.get_next_value(Kp);</code></p>
                                        <p align="left">Since I used Bluetooth to send commends in lab4 and lab5, I was able to reuse a lot of my functions such as <code>forward(), backward(), CW(), CCW(),</code> and <code>brake().</code> I also demonstrated my deployment of the IMU functionality onto the Bluetooth code in the Testing Methods section of my lab4 writeup.</p>
                                        <p align="left">After implementing all the debugging and helper functions, I am ready to move forward to implement PID control.</p>
                                    <p class="pre-wrap lead mb-3">PID Logic </p>
                                    <p align="left">A PID controller continuously calculates an error value as the difference between the desired setpoint and a measured process variable (output), and it applies a correction based on proportional (P), integral (I), and derivative (D) terms. The objective of this PID controller is to make the robot turn facing a certain direction. The key to implementing a PID controller is knowing what the setpoint, input, output, and error are. More importantly, knowing their units. In this case, the setpoint is the target angle, input is the yaw in degree calculated from the gyroscope z-axis data, the error is the difference between the current yaw and the setpoint, and the output is a number generated by the three PID terms. The P term is the product between a constant Kp and the error. The I term is the product of Ki and accumulated error. The D term is the product between Kd and the change of error. The unit of the output does not really matter. In this case, I use the sign of the output to decide if I should make the robot turn clockwise or counterclockwise, and the magnitude to control the motor speed. To make sure motor speed is in a reasonable range, I used a combination of min and max function to ensure its value. <code>motorspeed = min (230, max(150, output)); </code>
                                    </p>
                                    <p class="pre-wrap lead mb-3">PID Implementation and Tuning </p>
                                    <p align="left">Before tuning the controller, let me briefly summarize the significance of Kp, Ki, and Kd. The bigger Kp is, the harder the controller pushes. The smaller Ki is, the quicker the controller reacts to load changes, but the greater risk of oscillations. The bigger Kd is, the more the controller dampens oscillations. 
                                    </p>
                                    <p align="left">I implemented a controller with only the proportional term first. The value of Kp is arbitrary, but we can approximate the order of magnitude by considering that our output will become the input of analogWrite (0-255) and our error is (0-180) if we want the robot to turn backward. Therefore, I started with Kp equaled 1. 
                                    </p>
                                    <img class="img-fluid" src="assets/img/Lab6C1.png">
                                    <p align="left">I plotted the angle vs time, and I could see that system reached the setpoint correctly but it was a bit slow. Therefore, I kept increasing the Kp value. I observed overshoot when I set it to 3. </p>
                                    <img class="img-fluid" src="assets/img/Lab6C2.png">
                                    <p align="left">To suppress the overshoot while increasing the speed, even more, I increased the Kp to 4 and introduced a differential term. A big differential term slowed down the system, so I kept it small. As you can see, the overshoot is suppressed. </p>

                                    <img class="img-fluid" src="assets/img/Lab6C3.png">
                                    <p align="left">Since the robot turned fast and accurately with PD controls, my final implementation only include those two terms. 
                                    </p><img class="img-fluid" src="assets/img/Lab6:4.png">
                                    <p align="left">A worth noting debugging detail is that my gyroscope data was inaccurate at first. I then realized that the raw gyroscope data were maxed out. The gyroscope has an advanced setting that we can address, the maximal speed of the sensor. I increased in from the default 250 degree per second to 1000 with myFSS.g = dps1000;                                    </p>
                                    <p class="pre-wrap lead mb-3">Drifting Implementation </p>
                                    <p align="left">With effective closed-loop turning, all we need to do right now is to modify it so that it can move forward before and after. I set the initial setpoint to be 0, and change the setpoint in the middle of the run. I then ensured the robot moved forward when it is facing the setpoint direction by adding the if statement: <code>if (abs(error) < 2) { forward();}</code>
                                    And adding the pid turning code in the else statement.
                                    </p>
                                    <p class="pre-wrap lead mb-3">Demo</p>
                                    <p align="left">Here is the demo video for drifting. The robot traveled straight, turned exactly 180 degrees, and then traveled straight back. It performed the entire task at a relatively high speed.</p>
                                    <iframe src = "https://www.youtube.com/embed/o0zs07wxH40"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">Below are the data collected during this demo run.</p>
                                    <img class="img-fluid" src="assets/img/lab6C4.png">
                                    <img class="img-fluid" src="assets/img/lab6c5.png">
                                    <img class="img-fluid" src="assets/img/lab6c6.png">
                                    <iframe src = "https://www.youtube.com/embed/Z8X0P8SSXpY"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <iframe src = "https://www.youtube.com/embed/OfjwZr5vnvs"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p align="left">Below are the data collected during this demo run.</p>
                                    <img class="img-fluid" src="assets/img/lab6c7.png">
                                    <img class="img-fluid" src="assets/img/lab6c8.png">
                                    <img class="img-fluid" src="assets/img/lab6c9.png">
                                    <button class="btn btn-primary" href="#" data-dismiss="modal"><i class="fas fa-times fa-fw"></i>Close Window</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <section class="page-section bg-primary text-white mb-0" id="about">
            <div class="container">
                <!-- About Section Heading-->
                <div class="text-center">
                    <h2 class="page-section-heading d-inline-block text-white">ABOUT ME</h2>
                </div>
                <!-- Icon Divider-->
                <div class="divider-custom divider-light">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- About Section Content-->
                <div class="row">
                    <div class="col-lg-6 ">
                        <p class="pre-wrap lead mb-3">Hi, I am Robby, an ECE undergrad minor in Robotics.   I am an interdisciplinary engineer. <p class="pre-wrap lead">I lead the Electrical team of Cornell Electric Vehicles project team and develop double tail single actuated SAW robots in CEI Lab. I play soccer, ping pong, guitar, and do photography in my spare time. </p>
                    </div>
                    <div class="col ">
                        </div><img class="img-fluid" src="assets/img/headshot.jpg" width="410" height="150">
                    </div>
                    <div class="col mr-auto">
                        <p class="mb-5">  </p>
                    </div>
                </div>
            </div>
        </section>
        <section class="page-section" id="contact">
            <div class="container">
                <!-- Contact Section Heading-->
                <div class="text-center">
                    <h2 class="page-section-heading text-secondary d-inline-block mb-0">CONTACT</h2>
                </div>
                <!-- Icon Divider-->
                <div class="divider-custom">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- Contact Section Content-->
                <div class="row justify-content-center">
                    <div class="col-lg-4">
                        <div class="d-flex flex-column align-items-center">
                            <div class="icon-contact mb-3"><i class="fas fa-mobile-alt"></i></div>
                            <div class="text-muted">Phone</div>
                            <div class="lead font-weight-bold">(781) 417-9771</div>
                        </div>
                    </div>
                    <div class="col-lg-4">
                        <div class="d-flex flex-column align-items-center">
                            <div class="icon-contact mb-3"><i class="far fa-envelope"></i></div>
                            <div class="text-muted">Email</div><a class="lead font-weight-bold">lh479@cornell.edu</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- <footer class="footer text-center">
            <div class="container">
                <div class="row"> -->
                    <!-- Footer Location-->
                    <!-- <div class="col-lg-4 mb-5 mb-lg-0">
                        <h4 class="mb-4">LOCATION</h4>
                        <p class="pre-wrap lead mb-0">2215 John Daniel Drive
Clark, MO 65243</p>
                    </div> -->
                    <!-- Footer Social Icons-->
                    <!-- <div class="col-lg-4 mb-5 mb-lg-0">
                        <h4 class="mb-4">AROUND THE WEB</h4><a class="btn btn-outline-light btn-social mx-1" href="https://www.facebook.com/StartBootstrap"><i class="fab fa-fw fa-facebook-f"></i></a><a class="btn btn-outline-light btn-social mx-1" href="https://www.twitter.com/sbootstrap"><i class="fab fa-fw fa-twitter"></i></a><a class="btn btn-outline-light btn-social mx-1" href="https://www.linkedin.com/in/startbootstrap"><i class="fab fa-fw fa-linkedin-in"></i></a><a class="btn btn-outline-light btn-social mx-1" href="https://www.dribble.com/startbootstrap"><i class="fab fa-fw fa-dribbble"></i></a>
                    </div>-->
                    <!-- Footer About Text-->
                    <!-- <div class="col-lg-4">
                        <h4 class="mb-0">ABOUT FREELANCER</h4>
                        <p class="pre-wrap lead mb-0">Freelance is a free to use, MIT licensed Bootstrap theme created by Start Bootstrap</p>
                    </div>
                </div>
            </div>
        </footer> -->
        <!-- Copyright Section-->
        <section class="copyright py-4 text-center text-white">
            <div class="container"><small class="pre-wrap">Copyright © Robby Huang 2022</small></div>
        </section>
        <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes)-->
        <div class="scroll-to-top d-lg-none position-fixed"><a class="js-scroll-trigger d-block text-center text-white rounded" href="#page-top"><i class="fa fa-chevron-up"></i></a></div>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Contact form JS-->
        <script src="assets/mail/jqBootstrapValidation.js"></script>
        <script src="assets/mail/contact_me.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>